{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apb_3n0Kdlr0"
      },
      "source": [
        "import nltk\r\n",
        "from nltk import bigrams,trigrams \r\n",
        "from nltk.corpus import reuters\r\n",
        "from collections import Counter, defaultdict\r\n",
        "from gensim.test.utils import datapath\r\n",
        "from gensim.corpora import WikiCorpus as wkc\r\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jw7F08BfekW"
      },
      "source": [
        "wikidspath = datapath('enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2')\r\n",
        "sentences = wkc(wikidspath).get_texts()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP1DGUrffkY8",
        "outputId": "51e3ee4a-375a-4bdc-ca62-9b38ceaf17da"
      },
      "source": [
        "nltk.download('punkt')\r\n",
        "nltk.download('reuters')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQDD5OApfyEf"
      },
      "source": [
        "rs  = reuters.sents()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIsB39HchwTW",
        "outputId": "2841c261-fa7b-4388-eb06-bac6ec0f47fb"
      },
      "source": [
        "print(rs)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.'], ['They', 'told', 'Reuter', 'correspondents', 'in', 'Asian', 'capitals', 'a', 'U', '.', 'S', '.', 'Move', 'against', 'Japan', 'might', 'boost', 'protectionist', 'sentiment', 'in', 'the', 'U', '.', 'S', '.', 'And', 'lead', 'to', 'curbs', 'on', 'American', 'imports', 'of', 'their', 'products', '.'], ...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmtZvKYnfms_"
      },
      "source": [
        "def wordsProbability(sentenceModel):\r\n",
        "  for nextWord in sentenceModel:\r\n",
        "    nextWords = sentenceModel[nextWord]\r\n",
        "    totalWordCount = float(sum(nextWords.values()))\r\n",
        "    for previousWord in nextWords:\r\n",
        "      nextWords[previousWord] /= totalWordCount\r\n",
        "\r\n",
        "def singleWordProbability(sentenceModel,wordCount):\r\n",
        "  for word in sentenceModel:\r\n",
        "    sentenceModel[word] /= wordCount\r\n",
        "\r\n",
        "def convertToLower(s):\r\n",
        "  if type(s)==str:\r\n",
        "    return s.lower()\r\n",
        "  return s"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ8x-OZ6f7Bn"
      },
      "source": [
        "sentenceModel4 = defaultdict(lambda: set())\r\n",
        "sentenceModel5 = defaultdict(lambda: set())\r\n",
        "\r\n",
        "def calculateWordCount(sentenceModel1,sentenceModel2,sentenceModel3,sentences):\r\n",
        "  wordCount = 0\r\n",
        "  for sentence in sentences:\r\n",
        "    for word in sentence:\r\n",
        "      wordCount += 1\r\n",
        "      sentenceModel1[word] += 1\r\n",
        "    for previousWord2,previousWord1,nextWord in trigrams(sentence,pad_right=True,pad_left=True):\r\n",
        "      previousWord1 = convertToLower(previousWord1)\r\n",
        "      previousWord2 = convertToLower(previousWord2)\r\n",
        "      nextWord = convertToLower(nextWord)\r\n",
        "      sentenceModel2[nextWord][previousWord1] += 1 \r\n",
        "      sentenceModel3[nextWord][previousWord2] += 1\r\n",
        "      sentenceModel4[previousWord1].add(nextWord)\r\n",
        "      sentenceModel5[previousWord2].add(nextWord) \r\n",
        "\r\n",
        "  return wordCount"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trMYxbVwf-Fk",
        "outputId": "ba4e2cfb-4996-4f52-c4b4-94c381c02b11"
      },
      "source": [
        "sentenceModel1 = defaultdict(lambda:0)\r\n",
        "sentenceModel2 = defaultdict(lambda: defaultdict(lambda:0))\r\n",
        "sentenceModel3 = defaultdict(lambda: defaultdict(lambda:0))\r\n",
        "\r\n",
        "WikiWordCount = calculateWordCount(sentenceModel1,sentenceModel2,sentenceModel3,WikiSentences)\r\n",
        "print(WikiWordCount)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "452944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ59TaUXgAwz",
        "outputId": "8ff58f4d-2e65-4e0b-b4a8-4d124d95d759"
      },
      "source": [
        "ReutersWordCount = calculateWordCount(sentenceModel1,sentenceModel2,sentenceModel3,ReutersSentences)\r\n",
        "print(ReutersWordCount)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1720917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABZQ0_wXgGT9"
      },
      "source": [
        "calculateWordsProbabilities(sentenceModel2)\r\n",
        "calculateWordsProbabilities(sentenceModel3)\r\n",
        "\r\n",
        "totalWord = WikiWordCount + ReutersWordCount\r\n",
        "calculateSingleWordProbability(sentenceModel1,totalWord)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLrTLL-pgIWW"
      },
      "source": [
        "ProbabilityWordsList = [] \r\n",
        "\r\n",
        "def wordSuggestion(previousWord2,previousWord1): \r\n",
        "  for nextWord in sentenceModel4[previousWord1] & sentenceModel5[previousWord2]:\r\n",
        "    naiveBayesTrigramValue = sentenceModel1[nextWord]*sentenceModel2[nextWord][previousWord1]*sentenceModel3[nextWord][previousWord2]\r\n",
        "    ProbabilityWordsList.append((nextWord,naiveBayesTrigramValue))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV_Y_JGNgWxz",
        "outputId": "b84fba64-b4b4-4817-e6ae-59c58c9144f2"
      },
      "source": [
        "text = input(\"Text: \")\r\n",
        "ProbabilityWordsList = [] \r\n",
        "text = text.split(\" \")\r\n",
        "wordSuggestion(text[0],text[1])\r\n",
        "ProbabilityWordsList.sort(key=lambda o:o[1],reverse=True)\r\n",
        "print(*ProbabilityWordsList[:10])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: he needs\n",
            "('to', 1.559359364961502e-08) ('that', 7.821940408821843e-09) ('and', 3.094102899178931e-09) ('it', 2.8855892064629994e-09) ('the', 2.230569445442022e-09) ('in', 1.986452993509535e-09) ('this', 1.306849467794441e-09) ('more', 1.0849316336406677e-09) ('of', 8.868631958384381e-10)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}