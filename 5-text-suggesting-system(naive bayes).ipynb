{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apb_3n0Kdlr0"
      },
      "source": [
        "import nltk\r\n",
        "from nltk import bigrams,trigrams \r\n",
        "from nltk.corpus import reuters\r\n",
        "from collections import Counter, defaultdict\r\n",
        "from gensim.test.utils import datapath\r\n",
        "from gensim.corpora import WikiCorpus as wkc\r\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jw7F08BfekW"
      },
      "source": [
        "wikidspath = datapath('enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2')\r\n",
        "sentences = wkc(wikidspath).get_texts()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP1DGUrffkY8",
        "outputId": "51e3ee4a-375a-4bdc-ca62-9b38ceaf17da"
      },
      "source": [
        "nltk.download('punkt')\r\n",
        "nltk.download('reuters')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQDD5OApfyEf"
      },
      "source": [
        "rs  = reuters.sents()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIsB39HchwTW",
        "outputId": "2841c261-fa7b-4388-eb06-bac6ec0f47fb"
      },
      "source": [
        "print(rs)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.'], ['They', 'told', 'Reuter', 'correspondents', 'in', 'Asian', 'capitals', 'a', 'U', '.', 'S', '.', 'Move', 'against', 'Japan', 'might', 'boost', 'protectionist', 'sentiment', 'in', 'the', 'U', '.', 'S', '.', 'And', 'lead', 'to', 'curbs', 'on', 'American', 'imports', 'of', 'their', 'products', '.'], ...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmtZvKYnfms_"
      },
      "source": [
        "def wordsProbability(sentenceModel):\r\n",
        "  for nextWord in sentenceModel:\r\n",
        "    nextWords = sentenceModel[nextWord]\r\n",
        "    totalWordCount = float(sum(nextWords.values()))\r\n",
        "    for previousWord in nextWords:\r\n",
        "      nextWords[previousWord] /= totalWordCount\r\n",
        "\r\n",
        "def singleWordProbability(sentenceModel,wordCount):\r\n",
        "  for word in sentenceModel:\r\n",
        "    sentenceModel[word] /= wordCount\r\n",
        "\r\n",
        "def convertToLower(s):\r\n",
        "  if type(s)==str:\r\n",
        "    return s.lower()\r\n",
        "  return s"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ8x-OZ6f7Bn"
      },
      "source": [
        "sentenceModel4 = defaultdict(lambda: set()) # default value of model's keys is set as set\r\n",
        "sentenceModel5 = defaultdict(lambda: set())\r\n",
        "\r\n",
        "# calculating overall word count in the given sentence model\r\n",
        "def calculateWordCount(sentenceModel1,sentenceModel2,sentenceModel3,sentences):\r\n",
        "  wordCount = 0\r\n",
        "  for sentence in sentences:\r\n",
        "    for word in sentence:\r\n",
        "      wordCount += 1\r\n",
        "      sentenceModel1[word] += 1 #storing counts of each word in the first model\r\n",
        "    for previousWord2,previousWord1,nextWord in trigrams(sentence,pad_right=True,pad_left=True):\r\n",
        "      previousWord1 = convertToLower(previousWord1)\r\n",
        "      previousWord2 = convertToLower(previousWord2)\r\n",
        "      nextWord = convertToLower(nextWord)\r\n",
        "      sentenceModel2[nextWord][previousWord1] += 1 # storing count of just the previous words in case of specific word occuring\r\n",
        "      sentenceModel3[nextWord][previousWord2] += 1 # storing count of 2nd previous words in case of specific word occuring\r\n",
        "      sentenceModel4[previousWord1].add(nextWord) # adding new word based on the just previous word in the trigram to the sentence model\r\n",
        "      sentenceModel5[previousWord2].add(nextWord) # adding new word based on the 2nd previous word in the trigram to the sentence model\r\n",
        "\r\n",
        "  return wordCount"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trMYxbVwf-Fk",
        "outputId": "ba4e2cfb-4996-4f52-c4b4-94c381c02b11"
      },
      "source": [
        "sentenceModel1 = defaultdict(lambda:0)\r\n",
        "sentenceModel2 = defaultdict(lambda: defaultdict(lambda:0)) # The argument will be called when we try to access a key that doesn't exist\r\n",
        "sentenceModel3 = defaultdict(lambda: defaultdict(lambda:0))\r\n",
        "\r\n",
        "WikiWordCount = calculateWordCount(sentenceModel1,sentenceModel2,sentenceModel3,WikiSentences) # counting words in wiki corpus dataset\r\n",
        "print(WikiWordCount)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "452944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ59TaUXgAwz",
        "outputId": "8ff58f4d-2e65-4e0b-b4a8-4d124d95d759"
      },
      "source": [
        "ReutersWordCount = calculateWordCount(sentenceModel1,sentenceModel2,sentenceModel3,ReutersSentences) # counting words in Reuters dataset\r\n",
        "print(ReutersWordCount)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1720917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABZQ0_wXgGT9"
      },
      "source": [
        "calculateWordsProbabilities(sentenceModel2) # checking probabilities in model 2\r\n",
        "calculateWordsProbabilities(sentenceModel3) # checking probabilities in model 3\r\n",
        "\r\n",
        "totalWord = WikiWordCount + ReutersWordCount\r\n",
        "calculateSingleWordProbability(sentenceModel1,totalWord) # checking each word probability in model 1"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLrTLL-pgIWW"
      },
      "source": [
        "ProbabilityWordsList = [] \r\n",
        "# getting word suggestion by placing two words\r\n",
        "def WordSuggestionsByTrigram(previousWord2,previousWord1): \r\n",
        "  for nextWord in sentenceModel4[previousWord1] & sentenceModel5[previousWord2]:\r\n",
        "    naiveBayesTrigramValue = sentenceModel1[nextWord]*sentenceModel2[nextWord][previousWord1]*sentenceModel3[nextWord][previousWord2] # using naive bayes to get the weight of the each trigram \r\n",
        "    ProbabilityWordsList.append((nextWord,naiveBayesTrigramValue)) # storing the predicted words and the weights of trigram"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aymG6dAogOE-",
        "outputId": "e6dd4163-909a-4cb2-c34a-ce46de50100e"
      },
      "source": [
        "# test of suggestions given by placing words \"i have\" \r\n",
        "WordSuggestionsByTrigram('i','have')\r\n",
        "ProbabilityWordsList.sort(key=lambda o:o[1],reverse=True)\r\n",
        "print(*ProbabilityWordsList[:10])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc9WrrsdgPls",
        "outputId": "76c5891e-1b7d-4848-c5e7-55a1d74d9b2a"
      },
      "source": [
        "# test of suggestions given by placing words \"i have\" \r\n",
        "WordSuggestionsByTrigram('i','have')\r\n",
        "ProbabilityWordsList.sort(key=lambda o:o[1],reverse=True)\r\n",
        "print(*ProbabilityWordsList[:10])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV_Y_JGNgWxz",
        "outputId": "c6b61986-b642-48a3-abac-ee080e83cd00"
      },
      "source": [
        "text = input(\"Enter your Sentence: \")\r\n",
        "ProbabilityWordsList = [] \r\n",
        "text = text.split(\" \")\r\n",
        "WordSuggestionsByTrigram(text[0],text[1])\r\n",
        "ProbabilityWordsList.sort(key=lambda o:o[1],reverse=True)\r\n",
        "print(*ProbabilityWordsList[:10])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your Sentence: how to\n",
            "('reintegrate', 4.600110126636432e-07) ('quell', 4.600110126636432e-07) ('repay', 4.600110126636432e-07) ('implement', 4.181918296942211e-07) ('determine', 3.9429515371169415e-07) ('interpret', 3.577863431828336e-07) ('achieve', 3.517731273310212e-07) ('build', 3.517731273310212e-07) ('identify', 2.587561946232993e-07) ('make', 2.425512612226482e-07)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}